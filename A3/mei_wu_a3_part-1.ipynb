{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import re\n",
    "from operator import add\n",
    "\n",
    "# (8 cores, 16gb per machine) x 5 = 40 cores\n",
    "\n",
    "# New API\n",
    "spark_session = SparkSession\\\n",
    "        .builder\\\n",
    "        .master(\"spark://192.168.2.87:7077\") \\\n",
    "        .appName(\"mei_wu_part-1\")\\\n",
    "        .config(\"spark.dynamicAllocation.enabled\", True)\\\n",
    "        .config(\"spark.shuffle.service.enabled\", True)\\\n",
    "        .config(\"spark.dynamicAllocation.executorIdleTimeout\",\"30s\")\\\n",
    "        .config(\"spark.executor.cores\",4)\\\n",
    "        .getOrCreate()\n",
    "#        .config('spark.executor.cores', 2)\\\n",
    "\n",
    "\n",
    "# Old API (RDD)\n",
    "spark_context = spark_session.sparkContext\n",
    "\n",
    "rdd_en = spark_context.newAPIHadoopFile(\n",
    "    'hdfs://192.168.2.87:9000/europarl/europarl-v7.sv-en.en',\n",
    "    'org.apache.hadoop.mapreduce.lib.input.TextInputFormat',\n",
    "    'org.apache.hadoop.io.LongWritable',\n",
    "    'org.apache.hadoop.io.Text'\n",
    ")\\\n",
    ".cache() # Keep this RDD in memory!\n",
    "\n",
    "rdd_sv = spark_context.newAPIHadoopFile(\n",
    "    'hdfs://192.168.2.87:9000/europarl/europarl-v7.sv-en.sv',\n",
    "    'org.apache.hadoop.mapreduce.lib.input.TextInputFormat',\n",
    "    'org.apache.hadoop.io.LongWritable',\n",
    "    'org.apache.hadoop.io.Text'\n",
    ")\\\n",
    ".cache() # Keep this RDD in memory!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Number of lines, English: 1862234 and Swedish: 1862234. Number of Partitions, English: 2 and Swedish: 2. Verify the lines are of same length in both languages: True'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sv_count = rdd_sv.count() \n",
    "sv_count\n",
    "\n",
    "def rdd_checks(en, sv):\n",
    "    en_count = en.count() # A.1.1 Counts the lines in English\n",
    "    sv_count = sv.count() # A.1.2 Counts the lines in Swedish\n",
    "    \n",
    "    en_part = en.getNumPartitions() # A.1.4 Count number of partitions in English\n",
    "    sv_part = en.getNumPartitions()\n",
    "    \n",
    "    out_message = (f\"Number of lines, English: {en_count} and Swedish: {sv_count}. \" \n",
    "                   f\"Number of Partitions, English: {en_part} and Swedish: {sv_part}. \"\n",
    "                   f\"Verify the lines are of same length in both languages: {en_count == sv_count}\")\n",
    "    return out_message\n",
    "\n",
    "rdd_checks(rdd_en, rdd_sv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A.2.1\n",
    "def lowerNsplit(w):\n",
    "    w = w.lower().split(' ')\n",
    "    return w\n",
    "\n",
    "# A.2.2\n",
    "words_en = rdd_en.flatMapValues(lowerNsplit)\n",
    "words_en.take(10)\n",
    "\n",
    "test_en = spark_context.parallelize(rdd_en.take(100)).flatMapValues(lowerNsplit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A.2.2\n",
    "words_sv = rdd_sv.flatMapValues(lowerNsplit)\n",
    "words_sv.take(10)\n",
    "\n",
    "test_sv = spark_context.parallelize(rdd_sv.take(100)).flatMapValues(lowerNsplit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A.2.3 Verify that the line counts still match after the pre-processing.\n",
    "count_en = words_en.reduceByKey(lambda x, y: x).count()\n",
    "count_sv = words_sv.reduceByKey(lambda x, y: x).count()\n",
    "\n",
    "count_en == count_sv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 3498375),\n",
       " ('of', 1659758),\n",
       " ('to', 1539760),\n",
       " ('and', 1288401),\n",
       " ('in', 1085993),\n",
       " ('that', 797516),\n",
       " ('a', 773522),\n",
       " ('is', 758050),\n",
       " ('for', 534242),\n",
       " ('we', 522849)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A.3.1 Use Spark to compute the 10 most frequently according words in the English language corpus. Repeat for the other language.\n",
    "result_en = words_en.map(lambda x: (x[1], 1)).reduceByKey(add) # English\n",
    "result_sv = words_sv.map(lambda x: (x[1], 1)).reduceByKey(add) # Swedish\n",
    "\n",
    "# A.3.2 Verify that your results are reasonable.\n",
    "result_en.takeOrdered(10, key=lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('att', 1706293),\n",
       " ('och', 1344830),\n",
       " ('i', 1050774),\n",
       " ('det', 924866),\n",
       " ('som', 913276),\n",
       " ('för', 908680),\n",
       " ('av', 738068),\n",
       " ('är', 694381),\n",
       " ('en', 620310),\n",
       " ('vi', 539797)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A.3.2 Verify that your results are reasonable.\n",
    "result_sv.takeOrdered(10, key=lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A.4.1\n",
    "en = words_en.map(lambda x: (x[0], [ x[1] ]))\\\n",
    "                    .combineByKey(lambda value: (value, 1),\n",
    "                            lambda x, value: (x[0] + value, x[1] + 1),\n",
    "                            lambda x, y: (x[0] + y[0], x[1] + y[1]),\n",
    "                           )\n",
    "\n",
    "\n",
    "sv = words_sv.map(lambda x: (x[0], [ x[1] ]))\\\n",
    "                    .combineByKey(lambda value: (value, 1),\n",
    "                            lambda x, value: (x[0] + value, x[1] + 1),\n",
    "                            lambda x, y: (x[0] + y[0], x[1] + y[1]),\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ready_en = en.sortBy(lambda x: x[0]).map(lambda x: (x[1])).zipWithIndex().map(lambda x: (x[1],x[0]))\n",
    "ready_sv = sv.sortBy(lambda x: x[0]).map(lambda x: (x[1])).zipWithIndex().map(lambda x: (x[1],x[0]))\n",
    "\n",
    "\n",
    "joined = ready_en.join(ready_sv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('is', 'är'), 10040), (('we', 'vi'), 5530), (('i', 'jag'), 5020), (('this', 'detta'), 3252), (('closed.', 'avslutad.'), 2964), (('and', 'och'), 2917), (('a', 'en'), 2888), (('it', 'det'), 2866), (('that', 'det'), 2806), (('not', 'inte'), 2650)]\n"
     ]
    }
   ],
   "source": [
    "print(joined.filter(lambda x: x[1][1][1] != 0)\\\n",
    "      .filter(lambda x: x[1][0][1] < 10 and x[1][1][1] < 10)\\\n",
    "      .filter(lambda x: x[1][0][1] == x[1][1][1])\\\n",
    "      .map(lambda x: list( zip((x[1][0][0]),(x[1][1][0])) ))\\\n",
    "      .flatMap(lambda x: x)\\\n",
    "      .map(lambda x: (x, 1))\\\n",
    "      .reduceByKey(add)\\\n",
    "      .takeOrdered(10, key=lambda x: -x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_session.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
